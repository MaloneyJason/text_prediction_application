{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files into python \n",
    "reviews_train = []\n",
    "for line in open(\"../data/movie_data/full_train.txt\", 'r', encoding='utf-8'):\n",
    "    reviews_train.append(line.strip())\n",
    "    \n",
    "reviews_test = []\n",
    "for line in open(\"../data/movie_data/full_test.txt\", 'r', encoding='utf-8'):\n",
    "    reviews_test.append(line.strip())\n",
    "    \n",
    "target = [1 if i < 12500 else 0 for i in range(25000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This isn't the comedic Robin Williams, nor is it the quirky/insane Robin Williams of recent thriller fame. This is a hybrid of the classic drama without over-dramatization, mixed with Robin's new love of the thriller. But this isn't a thriller, per se. This is more a mystery/suspense vehicle through which Williams attempts to locate a sick boy and his keeper.<br /><br />Also starring Sandra Oh and Rory Culkin, this Suspense Drama plays pretty much like a news report, until William's character gets close to achieving his goal.<br /><br />I must say that I was highly entertained, though this movie fails to teach, guide, inspect, or amuse. It felt more like I was watching a guy (Williams), as he was actually performing the actions, from a third person perspective. In other words, it felt real, and I was able to subscribe to the premise of the story.<br /><br />All in all, it's worth a watch, though it's definitely not Friday/Saturday night fare.<br /><br />It rates a 7.7/10 from...<br /><br />the Fiend :.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "NO_SPACE = \"\"\n",
    "SPACE = \" \"\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    \n",
    "    reviews = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "reviews_test_clean = preprocess_reviews(reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"this isn't the comedic robin williams nor is it the quirky insane robin williams of recent thriller fame this is a hybrid of the classic drama without over dramatization mixed with robin's new love of the thriller but this isn't a thriller per se this is more a mystery suspense vehicle through which williams attempts to locate a sick boy and his keeper also starring sandra oh and rory culkin this suspense drama plays pretty much like a news report until william's character gets close to achieving his goal i must say that i was highly entertained though this movie fails to teach guide inspect or amuse it felt more like i was watching a guy williams as he was actually performing the actions from a third person perspective in other words it felt real and i was able to subscribe to the premise of the story all in all it's worth a watch though it's definitely not friday saturday night fare it rates a   from the fiend \""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train_clean[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_vectorizer = CountVectorizer(binary=True)\n",
    "# baseline_vectorizer.fit(reviews_train_clean)\n",
    "# X_baseline = baseline_vectorizer.transform(reviews_train_clean)\n",
    "# X_test_baseline = baseline_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X_baseline, target, train_size = 0.75\n",
    "# )\n",
    "\n",
    "# for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "#     lr = LogisticRegression(C=c)\n",
    "#     lr.fit(X_train, y_train)\n",
    "#     print (\"Accuracy for C=%s: %s\" \n",
    "#            % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "# #     Accuracy for C=0.01: 0.87328\n",
    "# #     Accuracy for C=0.05: 0.88368\n",
    "# #     Accuracy for C=0.25: 0.8832\n",
    "# #     Accuracy for C=0.5: 0.87872\n",
    "# #     Accuracy for C=1: 0.87648\n",
    "\n",
    "# final_model = LogisticRegression(C=0.05)\n",
    "# final_model.fit(X_baseline, target)\n",
    "# print (\"Final Accuracy: %s\" \n",
    "#        % accuracy_score(target, final_model.predict(X_test_baseline)))\n",
    "# # Final Accuracy: 0.88176"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "\n",
    "# english_stop_words = stopwords.words('english')\n",
    "# def remove_stop_words(corpus):\n",
    "#     removed_stop_words = []\n",
    "#     for review in corpus:\n",
    "#         removed_stop_words.append(\n",
    "#             ' '.join([word for word in review.split() \n",
    "#                       if word not in english_stop_words])\n",
    "#         )\n",
    "#     return removed_stop_words\n",
    "\n",
    "# no_stop_words_train = remove_stop_words(reviews_train_clean)\n",
    "# no_stop_words_test = remove_stop_words(reviews_test_clean)\n",
    "\n",
    "# cv = CountVectorizer(binary=True)\n",
    "# cv.fit(no_stop_words_train)\n",
    "# X = cv.transform(no_stop_words_train)\n",
    "# X_test = cv.transform(no_stop_words_test)\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X, target, train_size = 0.75\n",
    "# )\n",
    "\n",
    "# for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "#     lr = LogisticRegression(C=c)\n",
    "#     lr.fit(X_train, y_train)\n",
    "#     print (\"Accuracy for C=%s: %s\" \n",
    "#            % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_stemmed_text(corpus):\n",
    "#     from nltk.stem.porter import PorterStemmer\n",
    "#     stemmer = PorterStemmer()\n",
    "\n",
    "#     return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "# stemmed_reviews_train = get_stemmed_text(reviews_train_clean)\n",
    "# stemmed_reviews_test = get_stemmed_text(reviews_test_clean)\n",
    "\n",
    "# cv = CountVectorizer(binary=True)\n",
    "# cv.fit(stemmed_reviews_train)\n",
    "# X = cv.transform(stemmed_reviews_train)\n",
    "# X_test = cv.transform(stemmed_reviews_test)\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X, target, train_size = 0.75\n",
    "# )\n",
    "\n",
    "# for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "#     lr = LogisticRegression(C=c)\n",
    "#     lr.fit(X_train, y_train)\n",
    "#     print (\"Accuracy for C=%s: %s\" \n",
    "#            % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "# final_stemmed = LogisticRegression(C=0.05)\n",
    "# final_stemmed.fit(X, target)\n",
    "# print (\"Final Accuracy: %s\" \n",
    "#        % accuracy_score(target, final_stemmed.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_lemmatized_text(corpus):\n",
    "    \n",
    "#     from nltk.stem import WordNetLemmatizer\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "#     return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "# lemmatized_reviews_train = get_lemmatized_text(reviews_train_clean)\n",
    "# lemmatized_reviews_test = get_lemmatized_text(reviews_test_clean)\n",
    "\n",
    "# cv = CountVectorizer(binary=True)\n",
    "# cv.fit(lemmatized_reviews_train)\n",
    "# X = cv.transform(lemmatized_reviews_train)\n",
    "# X_test = cv.transform(lemmatized_reviews_test)\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X, target, train_size = 0.75\n",
    "# )\n",
    "\n",
    "# for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "#     lr = LogisticRegression(C=c)\n",
    "#     lr.fit(X_train, y_train)\n",
    "#     print (\"Accuracy for C=%s: %s\" \n",
    "#            % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "# final_lemmatized = LogisticRegression(C=0.25)\n",
    "# final_lemmatized.fit(X, target)\n",
    "# print (\"Final Accuracy: %s\" \n",
    "#        % accuracy_score(target, final_lemmatized.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n-grams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "# ngram_vectorizer.fit(reviews_train_clean)\n",
    "# X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "# X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X, target, train_size = 0.75\n",
    "# )\n",
    "\n",
    "# for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "#     lr = LogisticRegression(C=c)\n",
    "#     lr.fit(X_train, y_train)\n",
    "#     print (\"Accuracy for C=%s: %s\" \n",
    "#            % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "# # Accuracy for C=0.01: 0.88416\n",
    "# # Accuracy for C=0.05: 0.892\n",
    "# # Accuracy for C=0.25: 0.89424\n",
    "# # Accuracy for C=0.5: 0.89456\n",
    "# # Accuracy for C=1: 0.8944\n",
    "    \n",
    "# final_ngram = LogisticRegression(C=0.5)\n",
    "# final_ngram.fit(X, target)\n",
    "# print (\"Final Accuracy: %s\" \n",
    "#        % accuracy_score(target, final_ngram.predict(X_test)))\n",
    "\n",
    "# # Final Accuracy: 0.89784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# wc_vectorizer = CountVectorizer(binary=False)\n",
    "# wc_vectorizer.fit(reviews_train_clean)\n",
    "# X = wc_vectorizer.transform(reviews_train_clean)\n",
    "# X_test = wc_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X, target, train_size = 0.75, \n",
    "# )\n",
    "\n",
    "# for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "#     lr = LogisticRegression(C=c)\n",
    "#     lr.fit(X_train, y_train)\n",
    "#     print (\"Accuracy for C=%s: %s\" \n",
    "#            % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "# # Accuracy for C=0.01: 0.87456\n",
    "# # Accuracy for C=0.05: 0.88016\n",
    "# # Accuracy for C=0.25: 0.87936\n",
    "# # Accuracy for C=0.5: 0.87936\n",
    "# # Accuracy for C=1: 0.87696\n",
    "    \n",
    "# final_wc = LogisticRegression(C=0.05)\n",
    "# final_wc.fit(X, target)\n",
    "# print (\"Final Accuracy: %s\" \n",
    "#        % accuracy_score(target, final_wc.predict(X_test)))\n",
    "\n",
    "# # Final Accuracy: 0.88184"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# tfidf_vectorizer = TfidfVectorizer()\n",
    "# tfidf_vectorizer.fit(reviews_train_clean)\n",
    "# X = tfidf_vectorizer.transform(reviews_train_clean)\n",
    "# X_test = tfidf_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X, target, train_size = 0.75\n",
    "# )\n",
    "\n",
    "# for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "#     lr = LogisticRegression(C=c)\n",
    "#     lr.fit(X_train, y_train)\n",
    "#     print (\"Accuracy for C=%s: %s\" \n",
    "#            % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "\n",
    "# # Accuracy for C=0.01: 0.79632\n",
    "# # Accuracy for C=0.05: 0.83168\n",
    "# # Accuracy for C=0.25: 0.86768\n",
    "# # Accuracy for C=0.5: 0.8736\n",
    "# # Accuracy for C=1: 0.88432\n",
    "    \n",
    "# final_tfidf = LogisticRegression(C=1)\n",
    "# final_tfidf.fit(X, target)\n",
    "# print (\"Final Accuracy: %s\" \n",
    "#        % accuracy_score(target, final_tfidf.predict(X_test)))\n",
    "\n",
    "# # Final Accuracy: 0.88204"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "# ngram_vectorizer.fit(reviews_train_clean)\n",
    "# X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "# X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X, target, train_size = 0.75\n",
    "# )\n",
    "\n",
    "# for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "#     svm = LinearSVC(C=c)\n",
    "#     svm.fit(X_train, y_train)\n",
    "#     print (\"Accuracy for C=%s: %s\" \n",
    "#            % (c, accuracy_score(y_val, svm.predict(X_val))))\n",
    "    \n",
    "# # Accuracy for C=0.01: 0.89104\n",
    "# # Accuracy for C=0.05: 0.88736\n",
    "# # Accuracy for C=0.25: 0.8856\n",
    "# # Accuracy for C=0.5: 0.88608\n",
    "# # Accuracy for C=1: 0.88592\n",
    "    \n",
    "# final_svm_ngram = LinearSVC(C=0.01)\n",
    "# final_svm_ngram.fit(X, target)\n",
    "# print (\"Final Accuracy: %s\" \n",
    "#        % accuracy_score(target, final_svm_ngram.predict(X_test)))\n",
    "\n",
    "# # Final Accuracy: 0.9998"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Model - removing a small set of stop words along with an n-gram range from 1 to 3 and a linear support vector classifier gave me the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.001: 0.8856\n",
      "Accuracy for C=0.005: 0.89216\n",
      "Accuracy for C=0.01: 0.8944\n",
      "Accuracy for C=0.05: 0.89312\n",
      "Accuracy for C=0.1: 0.892\n",
      "Final Accuracy: 0.90064\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "stop_words = ['in', 'of', 'at', 'a', 'the']\n",
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3), stop_words=stop_words)\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75, random_state=2\n",
    ")\n",
    "\n",
    "for c in [0.001, 0.005, 0.01, 0.05, 0.1]:\n",
    "    \n",
    "    svm = LinearSVC(C=c)\n",
    "    svm.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, svm.predict(X_val))))\n",
    "    \n",
    "# Accuracy for C=0.001: 0.88784\n",
    "# Accuracy for C=0.005: 0.89456\n",
    "# Accuracy for C=0.01: 0.89376\n",
    "# Accuracy for C=0.05: 0.89264\n",
    "# Accuracy for C=0.1: 0.8928\n",
    "    \n",
    "final = LinearSVC(C=0.01)\n",
    "final.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final.predict(X_test)))\n",
    "\n",
    "# Final Accuracy: 0.90064"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 5358730)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# save the model to disk\n",
    "filename = 'SVM_model.sav'\n",
    "pickle.dump(final, open(filename, 'wb'))\n",
    "\n",
    "# save the CountVectorizer to disk\n",
    "filename = 'SVM_vect.sav'\n",
    "pickle.dump(ngram_vectorizer, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # top positive and negative features \n",
    "# feature_to_coef = {\n",
    "#     word: coef for word, coef in zip(\n",
    "#         ngram_vectorizer.get_feature_names(), final.coef_[0]\n",
    "#     )\n",
    "# }\n",
    "\n",
    "# for best_positive in sorted(\n",
    "#     feature_to_coef.items(), \n",
    "#     key=lambda x: x[1], \n",
    "#     reverse=True)[:30]:\n",
    "#     print (best_positive)\n",
    "    \n",
    "# print(\"\\n\\n\")\n",
    "# for best_negative in sorted(\n",
    "#     feature_to_coef.items(), \n",
    "#     key=lambda x: x[1])[:30]:\n",
    "#     print (best_negative)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
