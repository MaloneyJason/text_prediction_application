{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "from collections import defaultdict # for the model\n",
    "from nltk.util import ngrams\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n",
      "12500\n"
     ]
    }
   ],
   "source": [
    "# you need your machine's path \n",
    "# use * for the folder that has all the .txt files\n",
    "train_pos_filenames = glob.glob('/Users/jasonmaloney/Documents/Syracuse/IST 736 Text Mining/Text Mining Project/aclImdb/train/pos/*.txt')\n",
    "train_neg_filenames = glob.glob('/Users/jasonmaloney/Documents/Syracuse/IST 736 Text Mining/Text Mining Project/aclImdb/train/neg/*.txt')\n",
    "print(len(train_pos_filenames))\n",
    "print(len(train_neg_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_pos_text:\n",
      "for a movie that gets no respect there sure are a lot of memorable quotes listed for this gem. imagine a movie where joe piscopo is actually funny! maureen stapleton is a scene stealer. the moroni character is an absolute scream. watch for alan \"the skipper\" hale jr. as a police sgt.\n",
      "train_neg_text:\n",
      "working with one of the best shakespeare sources, this film manages to be creditable to it's source, whilst still appealing to a wider audience.branagh steals the film from under fishburne's nose, and there's a talented cast on good form.\n"
     ]
    }
   ],
   "source": [
    "# open file\n",
    "train_pos_text = []\n",
    "for filename in train_pos_filenames[:1000]:\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'\\n|<\\w+\\s/>', '', text)\n",
    "        train_pos_text.append(text)\n",
    "print(\"train_pos_text:\")\n",
    "print(train_pos_text[0])\n",
    "\n",
    "\n",
    "train_neg_text = []\n",
    "for filename in train_neg_filenames[:1000]:\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'\\n|<\\w+\\s/>', '', text)\n",
    "        train_neg_text.append(text)\n",
    "print(\"train_neg_text:\")\n",
    "print(train_neg_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get as a big long string\n",
    "words = ''\n",
    "for rev in train_pos_text:\n",
    "    words += ' ' + rev\n",
    "\n",
    "for rev in train_neg_text:\n",
    "    words += ' ' + rev\n",
    "\n",
    "# define tokenizer to get words\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# words has all the review as one string\n",
    "tokens = tokenizer.tokenize(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-gram model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of dictionaries\n",
    "# the inner function will take on counts (frequencies) \n",
    "# for probabilities\n",
    "four_gram_model = defaultdict(lambda: defaultdict(lambda: 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill up the dictionary\n",
    "for word1, word2, word3, word4 in ngrams(tokens, 4):\n",
    "     # increase the count (frequency of tokens)\n",
    "    four_gram_model[word1, word2, word3][word4] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the counts into probabilities\n",
    "for word1_word2_word3 in four_gram_model:\n",
    "    #print(word1_word2_word3)\n",
    "    # sum freq of all the first 3 word combos of each phrase\n",
    "    total_count = float(sum(four_gram_model[word1_word2_word3].values()))\n",
    "    # get each fourth word and divide each frequency by total count\n",
    "    # for conditional probabilities\n",
    "    for word4 in four_gram_model[word1_word2_word3]:\n",
    "        # get the probability\n",
    "        # four_gram_model[word1_word2_word3]/total_count\n",
    "        four_gram_model[word1_word2_word3][word4] /= total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Model Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_gram_model = defaultdict(lambda: defaultdict(lambda: 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word1, word2, word3, word4, word5 in ngrams(tokens, 5):\n",
    "    # increase the count (frequency for tokens)\n",
    "    four_gram_model[word1, word2, word3, word4][word5] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word1_word2_word3_word4 in five_gram_model:\n",
    "    #print(word1_word2_word3)\n",
    "    total_count = float(sum(five_gram_model[word1_word2_word3_word4].values()))\n",
    "    for word5 in four_gram_model[word1_word2_word4_word4]:\n",
    "        # get the probability\n",
    "        # four_gram_model[word1_word2_word3]/total_count\n",
    "        four_gram_model[word1_word2_word3_word4][word5] /= total_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Model Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
